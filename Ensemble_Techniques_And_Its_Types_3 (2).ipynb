{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Q1. What is Random Forest Regressor?\n",
        "\n",
        "ans. A **Random Forest Regressor** is a **machine learning algorithm** used for **regression tasks**, which means it is used to **predict continuous numerical values** (like predicting house prices, temperatures, sales, etc.).\n",
        "\n",
        "### Key Concepts:\n",
        "\n",
        "* **Random Forest** is an **ensemble method** — it combines the results of multiple models to improve accuracy and reduce overfitting.\n",
        "* It builds a large number of **decision trees** during training.\n",
        "* For regression, it **averages the predictions** of all the individual trees to give the final output.\n",
        "\n",
        "\n",
        "\n",
        "### How It Works:\n",
        "\n",
        "1. **Bootstrapping**: It creates multiple subsets of the training data by randomly sampling **with replacement**.\n",
        "2. **Training Decision Trees**: For each subset, it trains a **decision tree**.\n",
        "3. **Random Feature Selection**: At each split in the tree, it chooses a **random subset of features**, which introduces more diversity.\n",
        "4. **Prediction**:\n",
        "\n",
        "   * For regression, it **averages the outputs** of all the trees.\n",
        "   * For classification (in RandomForestClassifier), it takes the **majority vote**.\n",
        "\n",
        "\n",
        "\n",
        "### Advantages:\n",
        "\n",
        "* Handles non-linear relationships well.\n",
        "* Resistant to overfitting (more than a single decision tree).\n",
        "* Works well even if some data is missing or noisy.\n",
        "* Can handle both numerical and categorical features.\n",
        "\n"
      ],
      "metadata": {
        "id": "9WR59nQRzVpK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q2. How does Random Forest Regressor reduce the risk of overfitting?\n",
        "\n",
        "The **Random Forest Regressor** reduces overfitting by:\n",
        "\n",
        "1. **Averaging Predictions**: Combines outputs of many trees to smooth out noise and reduce variance.\n",
        "2. **Bootstrapping**: Trains each tree on a random sample of data, increasing model diversity.\n",
        "3. **Random Feature Selection**: At each split, considers only a subset of features, preventing trees from becoming too similar.\n",
        "4. **Model Constraints**: Parameters like `max_depth` and `min_samples_split` control tree complexity.\n",
        "\n",
        "These techniques together help avoid overfitting to the training data.\n"
      ],
      "metadata": {
        "id": "C1NizGklziuD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q3. How does Random Forest Regressor aggregate the predictions of multiple decision trees?\n",
        "\n",
        "ans. The **Random Forest Regressor** aggregates predictions by taking the **average** of the outputs from all the individual decision trees.\n",
        "\n",
        "### Steps:\n",
        "\n",
        "1. Each decision tree predicts a numeric value for the input.\n",
        "2. The final prediction is calculated as:\n",
        "\n",
        "$$\n",
        "\\text{Final Prediction} = \\frac{1}{n} \\sum_{i=1}^{n} \\text{Prediction}_i\n",
        "$$\n",
        "\n",
        "where $n$ is the number of trees.\n",
        "\n",
        "### Result:\n",
        "\n",
        "This averaging reduces variance and improves overall prediction accuracy.\n"
      ],
      "metadata": {
        "id": "AbTvGshwzxVe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q4. What are the hyperparameters of Random Forest Regressor?\n",
        "\n",
        "ans. Key **hyperparameters** of the **Random Forest Regressor** in `scikit-learn` include:\n",
        "\n",
        "1. **`n_estimators`**\n",
        "   Number of decision trees in the forest (default: 100).\n",
        "\n",
        "2. **`max_depth`**\n",
        "   Maximum depth of each tree. Controls overfitting.\n",
        "\n",
        "3. **`min_samples_split`**\n",
        "   Minimum number of samples required to split a node.\n",
        "\n",
        "4. **`min_samples_leaf`**\n",
        "   Minimum number of samples required to be at a leaf node.\n",
        "\n",
        "5. **`max_features`**\n",
        "   Number of features to consider when looking for the best split (e.g., \"auto\", \"sqrt\", \"log2\").\n",
        "\n",
        "6. **`bootstrap`**\n",
        "   Whether bootstrap samples are used when building trees (default: True).\n",
        "\n",
        "7. **`random_state`**\n",
        "   Controls randomness for reproducibility.\n",
        "\n",
        "8. **`n_jobs`**\n",
        "   Number of CPU cores used in parallel (e.g., -1 uses all cores).\n",
        "\n",
        "9. **`max_samples`**\n",
        "   If bootstrap is True, number of samples to draw from X to train each base estimator.\n",
        "\n",
        "These can be tuned using techniques like Grid Search or Random Search to improve model performance.\n"
      ],
      "metadata": {
        "id": "1wsgQakez6yN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q5. What is the difference between Random Forest Regressor and Decision Tree Regressor?\n",
        "\n",
        "\n",
        "ans.\n",
        "\n",
        "| Feature              | Decision Tree Regressor     | Random Forest Regressor           |\n",
        "| -------------------- | --------------------------- | --------------------------------- |\n",
        "| **Model Type**       | Single tree                 | Ensemble of multiple trees        |\n",
        "| **Overfitting Risk** | High                        | Lower (due to averaging)          |\n",
        "| **Variance**         | High                        | Reduced variance                  |\n",
        "| **Prediction**       | Direct output from one tree | Average of outputs from all trees |\n",
        "| **Training Time**    | Faster (only one tree)      | Slower (many trees trained)       |\n",
        "| **Accuracy**         | Often lower                 | Generally higher                  |\n",
        "| **Robustness**       | Sensitive to noise/outliers | More robust due to ensemble       |\n"
      ],
      "metadata": {
        "id": "shf6oU-80D_E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q6. What are the advantages and disadvantages of Random Forest Regressor?\n",
        "\n",
        "ans.  **Advantages of Random Forest Regressor**:\n",
        "\n",
        "1. **High Accuracy**: Combines multiple trees to improve predictive performance.\n",
        "2. **Reduces Overfitting**: Uses averaging and randomness to reduce variance.\n",
        "3. **Handles Non-linear Data**: Works well with complex relationships.\n",
        "4. **Robust to Outliers and Noise**: Less sensitive than single decision trees.\n",
        "5. **Feature Importance**: Provides insight into which features influence predictions.\n",
        "6. **Works with Missing Data**: Can handle some missing values.\n",
        "\n",
        "\n",
        "\n",
        "### **Disadvantages of Random Forest Regressor**:\n",
        "\n",
        "1. **Slower Predictions**: Due to multiple trees, inference time is higher.\n",
        "2. **Complexity**: Harder to interpret than a single decision tree.\n",
        "3. **Memory Usage**: Needs more memory to store many trees.\n",
        "4. **Not Ideal for Small Datasets**: May overfit or not perform better than simpler models on very small data.\n",
        "\n"
      ],
      "metadata": {
        "id": "3YPDyB4e0O1Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q7. What is the output of Random Forest Regressor?\n",
        "\n",
        "ans. The **output of a Random Forest Regressor** is a **continuous numerical value**, which is the **average prediction** from all the individual decision trees in the forest.\n",
        "\n",
        "### Example:\n",
        "\n",
        "If three trees predict:\n",
        "\n",
        "* Tree 1 → 200\n",
        "* Tree 2 → 220\n",
        "* Tree 3 → 210\n",
        "\n",
        "Then the output is:\n",
        "\n",
        "$$\n",
        "\\frac{200 + 220 + 210}{3} = 210\n",
        "$$\n",
        "\n",
        "This averaged value is the final regression prediction.\n"
      ],
      "metadata": {
        "id": "KVGQ4WDC0bM4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q8. Can Random Forest Regressor be used for classification tasks?\n",
        "\n",
        "ans. No, **Random Forest Regressor** is specifically designed for **regression tasks** (predicting continuous values).\n",
        "\n",
        "However, for **classification tasks** (predicting categories), you should use the **Random Forest Classifier** (`RandomForestClassifier` in `sklearn`), which predicts the class label by **majority voting** among the trees.\n",
        "\n",
        "### Summary:\n",
        "\n",
        "* Use **RandomForestRegressor** → for regression (e.g., predicting prices, temperatures).\n",
        "* Use **RandomForestClassifier** → for classification (e.g., predicting spam vs. not spam).\n"
      ],
      "metadata": {
        "id": "_nM1_G2h0id_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q7. What is the output of Random Forest Regressor?\n",
        "\n",
        "ans. The **output of a Random Forest Regressor** is the **average (mean) of the predictions made by all the individual decision trees** in the forest.\n",
        "\n",
        "### Here's how it works:\n",
        "\n",
        "* A Random Forest Regressor is an ensemble method that builds multiple decision trees on different subsets of the data and features.\n",
        "* Each decision tree gives a **numerical prediction** (since it's regression).\n",
        "* The final output of the model is the **mean of all these predictions**.\n",
        "\n",
        "### For example:\n",
        "\n",
        "If you have 5 decision trees and they predict:\n",
        "\n",
        "```\n",
        "Tree 1 → 4.2  \n",
        "Tree 2 → 4.8  \n",
        "Tree 3 → 4.5  \n",
        "Tree 4 → 4.0  \n",
        "Tree 5 → 4.6  \n",
        "```\n",
        "\n",
        "Then the **Random Forest Regressor output** will be:\n",
        "\n",
        "```\n",
        "(4.2 + 4.8 + 4.5 + 4.0 + 4.6) / 5 = 4.42\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "k5KS3vzln0X4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q8. Can Random Forest Regressor be used for classification tasks?\n",
        "\n",
        "ans. **Yes**, a Random Forest **can** be used for **classification tasks**, but in that case, it's called a **Random Forest Classifier**, **not** a Random Forest Regressor.\n",
        "\n",
        "### Key Differences:\n",
        "\n",
        "| Purpose           | Random Forest Regressor           | Random Forest Classifier                    |\n",
        "| ----------------- | --------------------------------- | ------------------------------------------- |\n",
        "| Task Type         | Regression (predict numbers)      | Classification (predict categories)         |\n",
        "| Output            | Average of tree outputs (numeric) | Majority vote of tree outputs (class label) |\n",
        "| Use Case Examples | Predicting prices, temperatures   | Spam detection, disease prediction          |\n",
        "\n",
        "### So:\n",
        "\n",
        "*  **Random Forest Regressor** → used for predicting **continuous values**\n",
        "*  **Random Forest Classifier** → used for **classification tasks**\n",
        "\n",
        "If you try to use the **Regressor** for classification, it will output continuous numbers, not class labels — which is **not appropriate** for classification.\n",
        "\n"
      ],
      "metadata": {
        "id": "hwwHScywoB7u"
      }
    }
  ]
}